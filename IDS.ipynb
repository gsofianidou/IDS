{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTlv+CNS1o3a1tqk9iEwGq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gsofianidou/IDS/blob/main/IDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "manbmBrqLBO3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import os\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "nclass = 12"
      ],
      "metadata": {
        "id": "nlDgFWzTLcz1"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadDataset():\n",
        "    # Put dataset path here !\n",
        "    filename='https://raw.githubusercontent.com/kdemertzis/EKPA/refs/heads/main/Data/pcap_data.csv'\n",
        "\n",
        "    trainfile = pd.read_csv(filename)\n",
        "    data = pd.DataFrame(trainfile).to_numpy()\n",
        "    data=data[data[:,25]!='DrDoS_LDAP']\n",
        "    np.random.shuffle(data)\n",
        "\n",
        "    label = data[:,25].astype('int')\n",
        "\n",
        "    label[label == 'WebDDoS']       = 0\n",
        "    label[label == 'BENIGN']        = 1\n",
        "    label[label == 'UDP-lag']       = 2\n",
        "    label[label == 'DrDoS_NTP']     = 3\n",
        "    label[label == 'Syn']           = 4\n",
        "    label[label == 'DrDoS_SSDP']    = 5\n",
        "    label[label == 'DrDoS_UDP']     = 6\n",
        "    label[label == 'DrDoS_NetBIOS'] = 7\n",
        "    label[label == 'DrDoS_MSSQL']   = 8\n",
        "    label[label == 'DrDoS_SNMP']    = 9\n",
        "    label[label == 'TFTP']          = 10\n",
        "    label[label == 'DrDoS_DNS']     = 11\n",
        "    #label[label == 'DrDoS_LDAP']     = 11\n",
        "\n",
        "    # SELECT FEATURES ----------------------------------------------------\n",
        "    inx_sel=-1+np.array([13, 6, 24, 17, 3, 9, 7, 14, 11, 21, 1, 22, 25, 17, 19, 26, 10,\n",
        "                         8, 20, 23, 18, 2, 15, 12, 16, 5, 4])\n",
        "\n",
        "    # MIN-MAX normalization\n",
        "    data=data[:,inx_sel]\n",
        "    dmin = data.min(axis=0)\n",
        "    dmax = data.max(axis=0)\n",
        "    data=(data-dmin)/(dmax-dmin)\n",
        "    # data = np.log(data-dmin+1.0)\n",
        "\n",
        "\n",
        "    # Test data 20%\n",
        "    train_data, test_data, train_label, test_label = \\\n",
        "        train_test_split(data, label, test_size=0.20, stratify=label)\n",
        "\n",
        "    # Train 70%, Validation %10\n",
        "    train_data, val_data, train_label, val_label = \\\n",
        "        train_test_split(train_data, train_label,test_size=0.125, stratify=train_label)\n",
        "\n",
        "\n",
        "    return train_data.astype('float32'), train_label.astype('int32'), \\\n",
        "        val_data.astype('float32'), val_label.astype('int32'), \\\n",
        "            test_data.astype('float32'), test_label.astype('int32')"
      ],
      "metadata": {
        "id": "8ZQ6Nt-iLj8F"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- LOAD DATA -----------------------------------------------------------------\n",
        "train_data, train_labelp, val_data, val_labelp, test_data, test_labelp = loadDataset()\n",
        "\n",
        "# to_categorical\n",
        "train_label = to_categorical(train_labelp, nclass)\n",
        "val_label   = to_categorical(val_labelp, nclass)\n",
        "test_label  = to_categorical(test_labelp, nclass)\n",
        "\n",
        "print('train_data.shape=', train_data.shape)\n",
        "print('test_data.shape=',  test_data.shape)\n",
        "print('test_data.shape=',  val_data.shape)\n",
        "\n",
        "#get the number of features\n",
        "inshape=train_data.shape[1]\n",
        "\n",
        "# Class balancing weights\n",
        "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
        "                                                  classes=np.unique(\n",
        "                                                      train_labelp),\n",
        "                                                  y=train_labelp)\n",
        "\n",
        "\n",
        "class_weights = {i: class_weights[i] for i in range(len(class_weights))}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wD0aQAqlMU-k",
        "outputId": "1077b3df-8b92-4a00-8f70-dd429b13fe71"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data.shape= (10476, 27)\n",
            "test_data.shape= (2994, 27)\n",
            "test_data.shape= (1497, 27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -- CALLBACKS -----------------------------------------------------------------\n",
        "earlyStopping = EarlyStopping(monitor='val_loss',\n",
        "                              patience=30,\n",
        "                              verbose=0,\n",
        "                              mode='min')\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"**FILE_NAME_HERE**.h5\",monitor='val_loss',verbose=1,mode='min',save_best_only=True,save_weights_only=False,period=1)\n",
        "modelCheckPoint = ModelCheckpoint('./savemodels/model5class.weights.{epoch:03d}-{val_acc:.4f}.hdf5',\n",
        "                                  save_best_only=True,\n",
        "                                  monitor='val_acc',\n",
        "                                  mode='max')\n",
        "\n",
        "# reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss',\n",
        "#                                   factor=0.1,\n",
        "#                                   patience=7,\n",
        "#                                   verbose=1,\n",
        "#                                   epsilon=1e-4,\n",
        "#                                   mode='min')\n",
        "\n",
        "# -- Baseline models-----------------------------------------------------------\n",
        "\n",
        "# -- Conv1d\n",
        "model=models_ddos.model_conv1D(lr=1e-4,N=64,inshape=inshape)\n",
        "# -- Dense\n",
        "# model=models_ddos.model_dense(lr=1e-4,N=64,inshape=inshape)\n",
        "# -- LSTM\n",
        "# model=models_ddos.model_lstm(lr=1e-4,N=64,inshape=inshape)\n",
        "\n",
        "model.summary()\n",
        "# -----------------------------------------------------------------------------\n",
        "# print model to an image file\n",
        "# dot_img_file = 'model1.png'\n",
        "# plot_model(model, to_file=dot_img_file, show_shapes=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "f7UAZEoTRbln",
        "outputId": "7fb5523f-5d09-40c2-864f-b208c03bafe5"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The filepath provided must end in `.keras` (Keras model format). Received: filepath=./savemodels/model5class.weights.{epoch:03d}-{val_acc:.4f}.hdf5",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-41620b6b4448>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                               mode='min')\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m modelCheckPoint = ModelCheckpoint('./savemodels/model5class.weights.{epoch:03d}-{val_acc:.4f}.hdf5',\n\u001b[0m\u001b[1;32m      8\u001b[0m                                   \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                   \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath, monitor, verbose, save_best_only, save_weights_only, mode, save_freq, initial_value_threshold)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    192\u001b[0m                     \u001b[0;34m\"The filepath provided must end in `.keras` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                     \u001b[0;34m\"(Keras model format). Received: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The filepath provided must end in `.keras` (Keras model format). Received: filepath=./savemodels/model5class.weights.{epoch:03d}-{val_acc:.4f}.hdf5"
          ]
        }
      ]
    }
  ]
}